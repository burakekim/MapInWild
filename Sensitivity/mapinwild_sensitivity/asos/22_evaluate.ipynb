{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tlib import tlearn\n",
    "from asos import settings, utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = settings.load_file_infos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction\n",
    "preds = utils.predict(*csv.df.index, classify=True, batch_size=64)\n",
    "\n",
    "# add preds to csv file\n",
    "csv.df['pred'] = np.array(tlearn.utils.preds_to_pred_labels(preds))\n",
    "csv.df['prob'] = np.array(tlearn.utils.preds_to_pred_probs(preds))\n",
    "csv.df['true_pred'] = csv.df['label'] == csv.df['pred']\n",
    "csv.save_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and plot metrics\n",
    "df_train = csv.df[csv.df['dataset'] == 'train']\n",
    "df_val = csv.df[csv.df['dataset'] == 'val']\n",
    "df_test = csv.df[csv.df['dataset'] == 'test']\n",
    "\n",
    "fig, ax = tlearn.metrics.plot_classification(\n",
    "    labels=[df_train['label'], df_val['label'], df_test['label']],\n",
    "    preds=[df_train['pred'], df_val['pred'], df_test['pred']],\n",
    "    probabilities=[df_train['prob'], df_val['prob'], df_test['prob']],\n",
    "    normalize='all',\n",
    "    titles=['train', 'val', 'test'],\n",
    "    figsize=(10, 10)\n",
    ")\n",
    "fig.savefig(os.path.join(settings.working_folder, 'evaluation.png'), facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot false predicted samples on map\n",
    "datasets = ['train', 'val', 'test']\n",
    "csv.plot_column(\n",
    "    column='true_pred',\n",
    "    df=csv.df[csv.df['dataset'].isin(datasets)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "plotter = utils.Plotter()\n",
    "plotter.plot(\n",
    "    file=csv.df.index[index],\n",
    "    plot_unet_maps=True,\n",
    "    plot_all_unet_maps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374c48dc1271b99c12a7b85dc001a616eb7f0880d8c9c6ea7642a00878377ce1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
